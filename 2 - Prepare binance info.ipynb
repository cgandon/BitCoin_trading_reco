{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import binance\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "\n",
    "X_columns = [\"gap\", \"overall_gap\", \"where_in_gap\", \"numTrades\"] # columns we will keep for 1st preprocessing steps\n",
    "#X_columns_final = [\"gap\", \"overall_gap\", \"where_in_gap\", \"numTrades\",\"buyer_is_maker\"]# columns we will keep for last preprocessing steps (after trades have been added)\n",
    "X_columns_final = [\"gap\",\"numTrades\",\"buyer_is_maker\"]# columns we will keep for last preprocessing steps (after trades have been added)\n",
    "y_columns = ['is_l100','is_l1000', 'is_h100','is_h1000'] # our Y columns\n",
    "time_step= 100 # how many time units used to explain each output\n",
    "\n",
    "check_steps = [10,100,1000,10000,50000,100000,150000] # used as monitoring steps for progress during long calculation processes\n",
    "\n",
    "start_point = '1544844000000' # timestamp (in ms) to start from: Dec 15th 2018, when we started data collection from\n",
    "current_point = 1556184840000 # current time: Apr 25th 11:34 am, when I started traininf the LSTM network\n",
    "\n",
    "low_limit = .0001 # values to ignore in your balance (Not Used yet, will be for further integration with Binance Portofolio)\n",
    "\n",
    "btcusd = 'BTCUSDT'# the exchange we're using as BTC valuation in USD\n",
    "\n",
    "\n",
    "# depth of history for min, hrs, day, month when we call Binance APIs\n",
    "depth_min = '1000'\n",
    "depth_hrs = '120'\n",
    "depth_day = '60'\n",
    "depth_mth = '5'\n",
    "\n",
    "keys = pd.read_csv(\"binancekey.csv\")# your APIs keys and Secret must be stored in a csv file on root directory.\n",
    "api_key = keys.loc[0,\"api_key\"]\n",
    "api_secret = keys.loc[0,\"api_secret\"]\n",
    "\n",
    "\n",
    "### Reusable function for time conversion\n",
    "\n",
    "# converts time stamp to standard date/time\n",
    "def clean_date(histo, value):\n",
    "    histo[\"closeTime\"] = histo[\"closeTime\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1000))\n",
    "    histo[\"openTime\"] = histo[\"openTime\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1000))\n",
    "    histo[\"xch\"] = value\n",
    "    return histo\n",
    "\n",
    "# collects history of valuations by minutes/day/hours/month. \n",
    "def build_histo(minutes, hours, days, months):\n",
    "    Hminutes = clean_date(pd.DataFrame(binance.klines(btcusd,minutes,limit = depth_min)),btcusd)\n",
    "    Hhours = clean_date(pd.DataFrame(binance.klines(btcusd,hours,limit = depth_hrs)), btcusd)\n",
    "    Hdays = clean_date(pd.DataFrame(binance.klines(btcusd,days,limit = depth_day)), btcusd)\n",
    "    Hmonths = clean_date(pd.DataFrame(binance.klines(btcusd,months,limit = depth_mth)), btcusd)\n",
    "    return Hminutes, Hhours, Hdays, Hmonths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>In previous steps we collected all data in small chunks (to be kind to Binance API), now let's rebuild 1 complete files from various archives of stocks values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir(\"data binance/archives stocks/\") # where your many small files are\n",
    "files.sort()\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for items in files: \n",
    "    temp = pd.read_csv('data binance/archives stocks/' + items, index_col = 0)\n",
    "    data = data.append(temp, ignore_index = True)\n",
    "data = clean_date(data,btcusd)\n",
    "data.to_csv(\"data binance/klines_all.csv\")\n",
    "\n",
    "# reload all Klines from file and reindex them (they may have gotten in wrong sequence when compounding small files together)\n",
    "data = pd.read_csv('data binance/klines_all.csv', index_col = 0)\n",
    "data = data.sort_values(\"openTime\")\n",
    "data = data.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same process with trades information\n",
    "rebuild 1 complete files from various archives of trades\n",
    "files = os.listdir(\"data binance/archives trades\")\n",
    "files.sort()\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for items in files: \n",
    "    temp = pd.read_csv('data binance/archives trades/' + items, index_col = 0)\n",
    "    data = data.append(temp, ignore_index = True)\n",
    "    print(items)\n",
    "#data[\"openTime\"] = data[\"T\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1000))\n",
    "data = data.sort_values(\"T\")\n",
    "data = data.reindex()\n",
    "data.to_csv(\"data binance/trades_all.csv\")\n",
    "# reload all Klines from file\n",
    "#data = pd.read_csv('trades_all.csv', index_col = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1>Let's now enrich our datasets. We will calculate for each line what is the highest and lowest value of the coming 100 and 1000 records. This will help us encode Y variables in next steps. At that stage I chose to keep both 100 and 1000 minutes approach since both may turn to be useful in future.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(data) - 1000):\n",
    "    \n",
    "    data.loc[i,\"lowest_of_100\"] = data.loc[i:i+99,\"low\"].min() # capture lowest of next 100\n",
    "    data.loc[i,\"lowest_of_1000\"] = data.loc[i:i+999,\"low\"].min() # capture lowest of next 1000\n",
    "\n",
    "    data.loc[i,\"highest_of_100\"] = data.loc[i:i+99,\"high\"].max() # record is highest of next 100\n",
    "    data.loc[i,\"highest_of_1000\"] = data.loc[i:i+999,\"high\"].max() # record is highest of next 1000\n",
    "\n",
    "# progress monitoring: this allows to control how far processing has gone in the file length          \n",
    "    if i in check_steps:\n",
    "        print(\"over {}\".format(i),datetime.datetime.fromtimestamp(time.time()))     \n",
    "        \n",
    "data.to_csv(\"data binance/with_lowest_of_10.csv\")    # make regular backup to flat file to avoid reprocessing all in case of problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data binance/with_lowest_of_10.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1> Let's optimize the input variable  </h1>\n",
    "\n",
    " \n",
    "* instead of a open/close value, let's rather collect the *gap* between open and close. This will give us a better trend, and be more abstract to context that a stock value\n",
    "* let's capture the overal gap between highest and lowest point, as volatility can be a sign of trend change\n",
    "* and let's capture where the closing is situated in this overal gap: rather on top? or on bottom?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"gap\"] = data[\"close\"] - data[\"open\"]\n",
    "data[\"overall_gap\"] = data[\"high\"] - data[\"low\"]\n",
    "data[\"where_in_gap\"] = data[\"close\"] - (data[\"high\"] + data[\"low\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1>Let's now encode our \"Y\" variables </h1>\n",
    "\n",
    "* is it the highest point of next 100 minutes?\n",
    "* is it the highest point of next 1000 minutes?\n",
    "* is it the lowest point of next 100 minutes?\n",
    "* is it the lowest point of next 1000 minutes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"with_lowest_of_10_v2.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"with_lowest_of_10_v2.csv\", index_col = 0)\n",
    "\n",
    "data[\"is_l100\"] = data.lowest_of_100 == data.low\n",
    "data[\"is_l1000\"] = data.lowest_of_1000 == data.low\n",
    "\n",
    "data[\"is_h100\"] = data.highest_of_100 == data.high\n",
    "data[\"is_h1000\"] = data.highest_of_1000 == data.high\n",
    "\n",
    "data[\"is_l100\"] = [int(r) for r in data[\"is_l100\"]]\n",
    "data[\"is_l1000\"] = [int(r) for r in data[\"is_l1000\"]]\n",
    "\n",
    "data[\"is_h100\"] = [int(r) for r in data[\"is_h100\"]]\n",
    "data[\"is_h1000\"] = [int(r) for r in data[\"is_h1000\"]]\n",
    "\n",
    "data.to_csv(\"with_lowest_of_10_v2.csv\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>GET TRADE INFO</H1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = pd.read_csv(\"data binance/Trades_all.csv\", index_col=0)\n",
    "data = pd.read_csv(\"data binance/with_lowest_of_10_v2.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades.index = trades[\"T\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1000)) # convert timestamp in std dateTime\n",
    "\n",
    "test1 = trades.resample(\"1min\",how=\"count\").rename({\"T\":\"openTime\"}, axis=1) # reaggregate trade counts per minute\n",
    "test1[\"openTime\"] = test1.index\n",
    "test2 = trades.resample(\"1min\",how=\"sum\").rename({\"T\":\"openTime\"}, axis=1)# reaggregate trade count for those which are \"Buyer is the maker\", per minute\n",
    "test2[\"openTime\"] = test2.index\n",
    "\n",
    "for i in range(len(data)):\n",
    "    tstp = data.loc[i,\"openTime\"]\n",
    "    try:\n",
    "        data.loc[i,\"buyer_is_maker\"] = test2.loc[tstp,\"m\"] / test1.loc[tstp,\"m\"] # for each minute of the dataset, enrich wiht the proportion of trades where buyer is maker\n",
    "    except:\n",
    "        data.loc[i,\"buyer_is_maker\"] = 0\n",
    "    if i in check_steps:\n",
    "        print(\"over {}\".format(i),datetime.datetime.now())         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(\"buyer_is_maker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data binance/with_lowest_of_10_and_trades.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> FILE OUTPUT </H1>\n",
    "\n",
    "* this is where we produce the file that will feed the neural network \n",
    "* The last 15% of the dataset are saved for further testing. \n",
    "* from the remaining 85%, we extract all records where y = 1, and provide and random sample of records where y = 0. This way, we balance our dataset. This is important because the proportion of y=1 is below 10%,  which could induce a distortion in the training of network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data binance/with_lowest_of_10_and_trades.csv\", index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "train_lim = int(len(data)*0.7) # training set length\n",
    "val_lim = int(len(data)*0.85)  # validation set length\n",
    "\n",
    "min_max_scaler = MinMaxScaler() # data are normalized\n",
    "fitted = min_max_scaler.fit(data.loc[:val_lim,X_columns_final])# normalization is fitted to train/val data only\n",
    "data[X_columns_final] = fitted.transform(data[X_columns_final])# tehn applied to the whole dataset\n",
    "\n",
    "data_temp = data # store temporarily 'data\n",
    "data = data.loc[time_step:val_lim,:] # skim data to build Train and Val, keep Test range untouched\n",
    "\n",
    "index_100 = []\n",
    "index_100.extend(data[data.is_l100 + data.is_h100 > 0].index) # collect all records with y = 1\n",
    "index_100.extend(data[data.is_l100 + data.is_h100 == 0].sample(len(index_100)).index) # collect a subset of records where y = 0\n",
    "index_100.sort()\n",
    "\n",
    "index_1000 = []\n",
    "index_1000.extend(data[data.is_l1000 + data.is_h1000 > 0].index)\n",
    "index_1000.extend(data[data.is_l1000 + data.is_h1000 == 0].sample(len(index_1000)).index)\n",
    "index_1000.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_temp #recover complete dataset\n",
    "\n",
    "t_f_100 = [(r in index_100) for r in data.index]  # build the range of items for train/val datasets\n",
    "t_f_1000 = [(r in index_1000) for r in data.index]\n",
    "\n",
    "data_100 = data[t_f_100] # build the train/val dataset\n",
    "data_1000 = data[t_f_1000]\n",
    "data_test = data[val_lim:len(data)-1000] # build the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# LSTM requires that each record carries it's history. We define depth of history wiht \"time_step\". This is done for both train/val sets (100 and 1000), and for the test file\n",
    "\n",
    "history = []\n",
    "for i in index_1000: \n",
    "    history.append(data.loc[i+1-time_step:i,X_columns_final].values) \n",
    "data_1000.loc[:,\"history\"] = history\n",
    "\n",
    "history = []\n",
    "for i in index_100: \n",
    "    history.append(data.loc[i+1-time_step:i,X_columns_final].values) \n",
    "data_100.loc[:,\"history\"] = history\n",
    "\n",
    "history = []\n",
    "for i in data_test.index: \n",
    "    history.append(data.loc[i+1-time_step:i,X_columns_final].values) \n",
    "data_test.loc[:,\"history\"] = history\n",
    "data_test.to_csv(\"traintest/test_data_backup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_train_file(data, y_col,pref):                \n",
    "                \n",
    "    X = data[\"history\"] \n",
    "    y = data[y_col]\n",
    "    \n",
    "    X = np.array([a for a in X])\n",
    "    y = np.array(y.values)\n",
    "    \n",
    "    train_lim = int(len(data)*0.85) # training set length\n",
    " \n",
    "    X_train = X[0:train_lim]\n",
    "    X_val = X[train_lim:]\n",
    "    y_train = y[0:train_lim]\n",
    "    y_val =  y[train_lim:]\n",
    "        \n",
    "    np.save(pref+'x_train',X_train)\n",
    "    np.save(pref+'x_val',X_val)\n",
    "    np.save(pref+'y_train',y_train)\n",
    "    np.save(pref+'y_val',y_val)\n",
    "#    return X_train\n",
    "\n",
    "def to_test_file(data, y_col,pref):\n",
    "    X = data[\"history\"] \n",
    "    y = data[y_col]\n",
    "\n",
    "    X = np.array([a for a in X])\n",
    "    y = np.array(y.values)\n",
    "        \n",
    "    np.save(pref+'x_test',X)\n",
    "    np.save(pref+'y_test',y)\n",
    "\n",
    "to_train_file(data_100,[\"is_l100\",\"is_h100\"],'traintest/100_')\n",
    "to_train_file(data_1000,[\"is_l1000\",\"is_h1000\"],'traintest/1000_')\n",
    "to_test_file(data_test,[\"is_l100\",\"is_h100\"],'traintest/100_')\n",
    "to_test_file(data_test,[\"is_l1000\",\"is_h1000\"],'traintest/1000_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67613412, 0.0112805 , 0.68210325, 0.01624519, 0.45942572])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Analysis of data distribution and variables behavior </h1>\n",
    "* this step intends to deep dive into the data set befor training it\n",
    "* trying to understand if the approach makes sense and if profit could ultimately come if we guess properly tops and bottoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data binance/with_lowest_of_10_v2.csv\", index_col = 0)\n",
    "data=data.loc[:,[\"gap\",\"overall_gap\",\"where_in_gap\",\"numTrades\",\"is_l100\",\"is_h100\"]]\n",
    "dl100y =data[data[\"is_l100\"]==1].describe()\n",
    "dl100n = data[data[\"is_l100\"]==0].describe()\n",
    "dh100y = data[data[\"is_h100\"]==1].describe()\n",
    "dh100n = data[data[\"is_h100\"]==0].describe()\n",
    "result=pd.DataFrame()\n",
    "for columns in X_columns:\n",
    "    result[\"is Low100\"] = dl100y[columns] \n",
    "    result[\"is not Low100\"] = dl100n[columns]\n",
    "    result[\"is High 100\"] = dh100y[columns]\n",
    "    result[\"is not High100\"] = dh100n[columns]\n",
    "    print(\"analysis of {}: \\n\".format(columns),\"\\n\",result,\"\\n\")\n",
    "\n",
    "sns.boxplot(x=data['is_l100'], y=data.gap[data[\"gap\"]**2 < 10])\n",
    "plt.show()\n",
    "sns.boxplot(x=data['is_h100'], y=data.gap[data[\"gap\"]**2 < 10])\n",
    "plt.show()\n",
    "\n",
    "print(\"is L100 \\n\",data[data[\"is_l100\"]==1].describe(), \"is not L100 \\n\",data[data[\"is_l100\"]==0].describe())\n",
    "print(\"is H100 \\n\",data[data[\"is_h100\"]==1].describe(), \"is not H100 \\n\",data[data[\"is_h100\"]==0].describe())\n",
    "\n",
    "print(\"behavior of volume for low spot \\n\")\n",
    "sns.boxplot(x=data['is_l100'], y=data[\"volume\"])\n",
    "plt.show()\n",
    "\n",
    "print(\"behavior of volume for high spot \\n\")\n",
    "sns.boxplot(x=data['is_h100'], y=data[\"volume\"])\n",
    "plt.show()\n",
    "\n",
    "print(\"behavior of buyer_is_maker for low spot \\n\")\n",
    "sns.boxplot(x=data[\"is_l100\"],y=data.loc[data[\"buyer_is_maker\"] > .4,\"buyer_is_maker\"])\n",
    "plt.show()\n",
    "\n",
    "print(\"behavior of buyer is maker for high spot \\n\")\n",
    "sns.boxplot(x=data[\"is_h100\"],y=data.loc[data[\"buyer_is_maker\"] > .4,\"buyer_is_maker\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> How much would we have made if we had been able to spot the best 10 trades?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data binance/with_lowest_of_10_v2.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_for = 'buy'\n",
    "buy_price = .0\n",
    "for i in range(len(data)-1):\n",
    "    if look_for == 'buy' and data.loc[i,\"is_l100\"]==1:\n",
    "        buy_price = data.loc[i,\"low\"]\n",
    "        buy_time = i\n",
    "        look_for = \"sell\"\n",
    "    elif look_for == 'sell' and data.loc[i,\"is_h100\"]==1:\n",
    "        data.loc[i,\"profit\"] = 0.99*data.loc[i,\"high\"] - buy_price # a penalty of 1% is applied to represent trade fees applied by excahnge  platform\n",
    "        data.loc[i,\"immo_time\"] = i - buy_time\n",
    "        look_for = \"buy\"\n",
    "    if i in check_steps:\n",
    "        print(\"over {}\".format(i),datetime.datetime.now())     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Profit distribution** \n",
    "\n",
    "* zooming on 25/75 quartiles (1st graph) shows that half of transactions hits a profits from -20 to +20\n",
    "* but the global picture (second graph) shows that thanks to occasional exceptional gains, the average gain is positive\n",
    "* this is how we get a median of -4 along with a mean of 9.95\n",
    "* we also notice the the average investment duration is 118 minutes between buy and sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zoom on profit obtained:\n",
      "            profit   immo_time\n",
      "count  879.000000  879.000000\n",
      "mean     9.953841  118.982935\n",
      "std     48.600023   82.658288\n",
      "min    -35.277400    1.000000\n",
      "25%    -16.047250   57.000000\n",
      "50%     -4.180000  103.000000\n",
      "75%     18.701350  160.500000\n",
      "max    652.485600  481.000000\n",
      "\n",
      " median = -4.180000000000291 and mean = 9.95384141069391\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1eff4240>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"zoom on profit obtained:\\n\", data[[\"profit\",\"immo_time\"]].describe())\n",
    "sns.boxplot(y = data.profit[data[\"profit\"]<60])\n",
    "print(\"\\n median = {} and mean = {}\".format(data[\"profit\"].median(),data[\"profit\"].mean() ))\n",
    "plt.show()\n",
    "sns.boxplot(y = data[\"profit\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Focusing on the top trades (ranked by descending profit) we can also conclude that being selective is key. Most trades will generate a profit close to 0 or even negative, mostly because of trading fees. \n",
    "* however, if we manage to trigger trades only on best situations, we can be largely positive.\n",
    "* the top 20 trades of the last 5 months alone would have generated a nearly 100% profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total gain realised with 20 trades:4708.8\n",
      "natural growth of market: 3251.54 - 5403.35 = 4708.8\n",
      "20 best trades outperforms market: 219.0%\n"
     ]
    }
   ],
   "source": [
    "n_trades = 20\n",
    "top_trades = round(data.sort_values(\"profit\", ascending=False).head(n_trades)[[\"immo_time\",\"profit\"]].describe(),2)\n",
    "achieved_profit = top_trades[\"profit\"][\"mean\"]*n_trades\n",
    "mkt_g = round(data.loc[len(data)-1,\"close\"] - data.loc[0,\"close\"],2)\n",
    "\n",
    "print(\"total gain realised with {} trades:{}\".format(n_trades,achieved_profit))\n",
    "print(\"natural growth of market: {} - {} = {}\".format(data.loc[0,\"close\"],data.loc[len(data)-1,\"close\"],achieved_profit))\n",
    "print(\"{} best trades outperforms market: {}%\".format(n_trades,round(achieved_profit / mkt_g * 100),2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's be more realistic and assume that we get the top 20 and worst 20 of the trades\n",
    "* the trades still outperform the market "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total gain realised with 20 best and worst trades:4098.400000000001\n",
      "natural growth of market: 3251.54 - 5403.35 = 4098.400000000001\n",
      "20 best trades outperforms market: 190.0%\n"
     ]
    }
   ],
   "source": [
    "n_trades = 20\n",
    "top_trades = round(data.sort_values(\"profit\", ascending=False).head(n_trades)[[\"immo_time\",\"profit\"]].describe(),2)\n",
    "worst_trades = round(data.sort_values(\"profit\", ascending=True).head(n_trades)[[\"immo_time\",\"profit\"]].describe(),2)\n",
    "\n",
    "achieved_profit = top_trades[\"profit\"][\"mean\"]*n_trades + worst_trades[\"profit\"][\"mean\"]*n_trades\n",
    "mkt_g = round(data.loc[len(data)-1,\"close\"] - data.loc[0,\"close\"],2)\n",
    "\n",
    "print(\"total gain realised with {} best and worst trades:{}\".format(n_trades,achieved_profit))\n",
    "print(\"natural growth of market: {} - {} = {}\".format(data.loc[0,\"close\"],data.loc[len(data)-1,\"close\"],achieved_profit))\n",
    "print(\"{} best trades outperforms market: {}%\".format(n_trades,round(achieved_profit / mkt_g * 100),2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
