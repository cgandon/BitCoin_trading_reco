{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import binance\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "# timestamp (in ms) to start from: Dec 15th 2018\n",
    "start_point = '1544844000000'\n",
    "\n",
    "# current time: Apr 25th 11:34 am\n",
    "current_point = 1556184840000\n",
    "\n",
    "# values to ignore in your balance\n",
    "low_limit = .0001 \n",
    "\n",
    "# reference exchange for BTC valuation\n",
    "btcusd = 'BTCUSDT'\n",
    "\n",
    "# depth of history for min, hrs, day, month\n",
    "depth_min = '1000'\n",
    "depth_hrs = '120'\n",
    "depth_day = '60'\n",
    "depth_mth = '5'\n",
    "\n",
    "keys = pd.read_csv(\"binancekey.csv\")\n",
    "api_key = keys.loc[0,\"api_key\"]\n",
    "api_secret = keys.loc[0,\"api_secret\"]\n",
    "binance.set(api_key, api_secret)\n",
    "\n",
    "### fonctions r√©utilisables\n",
    "\n",
    "# build function that converts time stamp to standard date/time\n",
    "def clean_date(histo, value):\n",
    "    histo[\"closeTime\"] = histo[\"closeTime\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1000))\n",
    "    histo[\"openTime\"] = histo[\"openTime\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1000))\n",
    "    histo[\"xch\"] = value\n",
    "    return histo\n",
    "\n",
    "# build function that collects history by minutes/day/hours/month. \n",
    "def build_histo(minutes, hours, days, months):\n",
    "    Hminutes = clean_date(pd.DataFrame(binance.klines(btcusd,minutes,limit = depth_min)),btcusd)\n",
    "    Hhours = clean_date(pd.DataFrame(binance.klines(btcusd,hours,limit = depth_hrs)), btcusd)\n",
    "    Hdays = clean_date(pd.DataFrame(binance.klines(btcusd,days,limit = depth_day)), btcusd)\n",
    "    Hmonths = clean_date(pd.DataFrame(binance.klines(btcusd,months,limit = depth_mth)), btcusd)\n",
    "    return Hminutes, Hhours, Hdays, Hmonths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rebuild 1 complete files from various archives\n",
    "files = os.listdir(\"data binance/\")\n",
    "files.sort()\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for items in files: \n",
    "    temp = pd.read_csv('data binance/' + items, index_col = 0)\n",
    "    data = data.append(temp, ignore_index = True)\n",
    "data = clean_date(data,btcusd)\n",
    "data.to_csv(\"klines_all.csv\")\n",
    "# reload all Klines from file\n",
    "data = pd.read_csv('klines_all.csv', index_col = 0)\n",
    "data = data.sort_values(\"openTime\")\n",
    "data = data.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# feature engineering: categorize records indicating if they are highest or lowest of next x rows\n",
    "\n",
    "for i in range(0,len(data) - 1000):\n",
    "    \n",
    "    data.loc[i,\"lowest_of_10\"] = data.loc[i:i+9,\"low\"].min() # capture lowest of next 10\n",
    "    data.loc[i,\"lowest_of_50\"] = data.loc[i:i+49,\"low\"].min() # capture lowest of next 50\n",
    "    data.loc[i,\"lowest_of_100\"] = data.loc[i:i+99,\"low\"].min() # capture lowest of next 100\n",
    "    data.loc[i,\"lowest_of_1000\"] = data.loc[i:i+999,\"low\"].min() # capture lowest of next 1000\n",
    "\n",
    "    data.loc[i,\"highest_of_10\"] = data.loc[i:i+9,\"high\"].max() # record is highest of next 10\n",
    "    data.loc[i,\"highest_of_50\"] = data.loc[i:i+49,\"high\"].max() # record is highest of next 50\n",
    "    data.loc[i,\"highest_of_100\"] = data.loc[i:i+99,\"high\"].max() # record is highest of next 100\n",
    "    data.loc[i,\"highest_of_1000\"] = data.loc[i:i+999,\"high\"].max() # record is highest of next 1000\n",
    "\n",
    "# progress monitoring        \n",
    "    \n",
    "    if i == 100:\n",
    "        print(\"over 100\",datetime.datetime.fromtimestamp(time.time()))       \n",
    "    if i == 10000:\n",
    "        print(\"over 10k\",datetime.datetime.fromtimestamp(time.time()))\n",
    "    if i == 50000:\n",
    "        print(\"over 50k\",datetime.datetime.fromtimestamp(time.time()))\n",
    "    if i == 100000:\n",
    "        print(\"over 100k\",datetime.datetime.fromtimestamp(time.time()))\n",
    "    if i == 150000:\n",
    "        print('over 150k',datetime.datetime.fromtimestamp(time.time()))\n",
    "        \n",
    "data.to_csv(\"with_lowest_of_10.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"with_lowest_of_10.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' patch\n",
    "data[\"lowest_of_1000\"] = 0\n",
    "data[\"highest_of_1000\"] = 0\n",
    "\n",
    "for i in range(0,len(data) - 1000): \n",
    "    if data.loc[i,\"is_l100\"] == 1:\n",
    "        data.loc[i,\"lowest_of_1000\"] = data.loc[i:i+999,\"low\"].min() # capture lowest of next 1000\n",
    "    if data.loc[i,\"is_h100\"] == 1:\n",
    "        data.loc[i,\"highest_of_1000\"] = data.loc[i:i+999,\"high\"].max() # record is highest of next 1000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# enrichissement avec les pointeurs\n",
    "data[\"is_l10\"] = data.lowest_of_10 == data.low\n",
    "data[\"is_l50\"] = data.lowest_of_50 == data.low\n",
    "data[\"is_l100\"] = data.lowest_of_100 == data.low\n",
    "data[\"is_l1000\"] = data.lowest_of_1000 == data.low\n",
    "\n",
    "data[\"is_h10\"] = data.highest_of_10 == data.high\n",
    "data[\"is_h50\"] = data.highest_of_50 == data.high\n",
    "data[\"is_h100\"] = data.highest_of_100 == data.high\n",
    "data[\"is_h1000\"] = data.highest_of_1000 == data.high\n",
    "\n",
    "data[\"is_l10\"] = [int(r) for r in data[\"is_l10\"]]\n",
    "data[\"is_l50\"] = [int(r) for r in data[\"is_l50\"]]\n",
    "data[\"is_l100\"] = [int(r) for r in data[\"is_l100\"]]\n",
    "data[\"is_l1000\"] = [int(r) for r in data[\"is_l1000\"]]\n",
    "\n",
    "data[\"is_h10\"] = [int(r) for r in data[\"is_h10\"]]\n",
    "data[\"is_h50\"] = [int(r) for r in data[\"is_h50\"]]\n",
    "data[\"is_h100\"] = [int(r) for r in data[\"is_h100\"]]\n",
    "data[\"is_h1000\"] = [int(r) for r in data[\"is_h1000\"]]\n",
    "\n",
    "data.to_csv(\"with_lowest_of_10.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"with_lowest_of_10.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>closeTime</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>numTrades</th>\n",
       "      <th>open</th>\n",
       "      <th>openTime</th>\n",
       "      <th>quoteVolume</th>\n",
       "      <th>volume</th>\n",
       "      <th>xch</th>\n",
       "      <th>...</th>\n",
       "      <th>is_l10</th>\n",
       "      <th>is_l50</th>\n",
       "      <th>is_l100</th>\n",
       "      <th>is_h10</th>\n",
       "      <th>is_h50</th>\n",
       "      <th>is_h100</th>\n",
       "      <th>highest_of_1000</th>\n",
       "      <th>lowest_of_1000</th>\n",
       "      <th>is_h1000</th>\n",
       "      <th>is_l1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3251.54</td>\n",
       "      <td>2018-12-15 04:20:59.999</td>\n",
       "      <td>3252.77</td>\n",
       "      <td>3250.27</td>\n",
       "      <td>89</td>\n",
       "      <td>3250.27</td>\n",
       "      <td>2018-12-15 04:20:00</td>\n",
       "      <td>27264.262578</td>\n",
       "      <td>8.385634</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3251.66</td>\n",
       "      <td>2018-12-15 04:21:59.999</td>\n",
       "      <td>3253.72</td>\n",
       "      <td>3250.41</td>\n",
       "      <td>105</td>\n",
       "      <td>3251.54</td>\n",
       "      <td>2018-12-15 04:21:00</td>\n",
       "      <td>36756.847331</td>\n",
       "      <td>11.303379</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3248.80</td>\n",
       "      <td>2018-12-15 04:22:59.999</td>\n",
       "      <td>3251.16</td>\n",
       "      <td>3248.79</td>\n",
       "      <td>121</td>\n",
       "      <td>3250.79</td>\n",
       "      <td>2018-12-15 04:22:00</td>\n",
       "      <td>45509.798550</td>\n",
       "      <td>14.002981</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3248.47</td>\n",
       "      <td>2018-12-15 04:23:59.999</td>\n",
       "      <td>3249.92</td>\n",
       "      <td>3247.83</td>\n",
       "      <td>114</td>\n",
       "      <td>3249.43</td>\n",
       "      <td>2018-12-15 04:23:00</td>\n",
       "      <td>48525.647730</td>\n",
       "      <td>14.937206</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3247.37</td>\n",
       "      <td>2018-12-15 04:24:59.999</td>\n",
       "      <td>3249.37</td>\n",
       "      <td>3246.60</td>\n",
       "      <td>105</td>\n",
       "      <td>3247.81</td>\n",
       "      <td>2018-12-15 04:24:00</td>\n",
       "      <td>43017.224148</td>\n",
       "      <td>13.243858</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     close                closeTime     high      low  numTrades     open  \\\n",
       "0  3251.54  2018-12-15 04:20:59.999  3252.77  3250.27         89  3250.27   \n",
       "1  3251.66  2018-12-15 04:21:59.999  3253.72  3250.41        105  3251.54   \n",
       "2  3248.80  2018-12-15 04:22:59.999  3251.16  3248.79        121  3250.79   \n",
       "3  3248.47  2018-12-15 04:23:59.999  3249.92  3247.83        114  3249.43   \n",
       "4  3247.37  2018-12-15 04:24:59.999  3249.37  3246.60        105  3247.81   \n",
       "\n",
       "              openTime   quoteVolume     volume      xch  ...  is_l10  is_l50  \\\n",
       "0  2018-12-15 04:20:00  27264.262578   8.385634  BTCUSDT  ...       0       0   \n",
       "1  2018-12-15 04:21:00  36756.847331  11.303379  BTCUSDT  ...       0       0   \n",
       "2  2018-12-15 04:22:00  45509.798550  14.002981  BTCUSDT  ...       0       0   \n",
       "3  2018-12-15 04:23:00  48525.647730  14.937206  BTCUSDT  ...       0       0   \n",
       "4  2018-12-15 04:24:00  43017.224148  13.243858  BTCUSDT  ...       0       0   \n",
       "\n",
       "   is_l100  is_h10  is_h50  is_h100  highest_of_1000  lowest_of_1000  \\\n",
       "0        0       0       0        0              0.0             0.0   \n",
       "1        0       1       0        0              0.0             0.0   \n",
       "2        0       1       0        0              0.0             0.0   \n",
       "3        0       1       0        0              0.0             0.0   \n",
       "4        0       0       0        0              0.0             0.0   \n",
       "\n",
       "   is_h1000  is_l1000  \n",
       "0         0         0  \n",
       "1         0         0  \n",
       "2         0         0  \n",
       "3         0         0  \n",
       "4         0         0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remains to do:\n",
    "# try with is_l10/50/100 as input variable rather than output\n",
    "# eliminate islxxx from latest records of each training set because in reality we won't know\n",
    "# try and normalize each training set individually to keep only short term contextual behabiour\n",
    "# try and tag each line with a realationship to MA50, 100, etc...\n",
    "\n",
    "data = pd.read_csv(\"with_lowest_of_10.csv\", index_col = 0)\n",
    "data = data.loc[:len(data)-1000,:]# eliminate last 1000 records which are not enriched\n",
    "\n",
    "data[\"gap\"] = data[\"close\"] - data[\"open\"]\n",
    "data[\"overall_gap\"] = data[\"high\"] - data[\"low\"]\n",
    "data[\"where_in_gap\"] = data[\"close\"] - (data[\"high\"] + data[\"low\"])/2\n",
    "\n",
    "#X_columns = [\"gap\", \"overall_gap\", \"where_in_gap\", \"numTrades\"]\n",
    "X_columns = [\"close\"]\n",
    "\n",
    "y_columns = ['is_l10', 'is_l50','is_l100','is_l1000', 'is_h10','is_h50', 'is_h100','is_h1000']\n",
    "\n",
    "time_step= 1000 # how many time units used to explain each output\n",
    "\n",
    "#X = np.array(data.loc[:, X_columns])\n",
    "#y = np.array(data.loc[:, y_columns])\n",
    "X = data.loc[:, X_columns]\n",
    "y = data.loc[:, y_columns]\n",
    "\n",
    "dim_0 = X.shape[0] # final training set \n",
    "dim_1 = X.shape[1] # how many dimension each record has\n",
    "dim_2 = y.shape[1] # how many output neurons \n",
    "\n",
    "\n",
    "train_lim = int(dim_0 *0.7) # training set length\n",
    "val_lim = int(dim_0*0.85)  # validation set length\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "fitted = min_max_scaler.fit(X[:val_lim]) # don't fit on test data\n",
    "X = fitted.transform(X) \n",
    "X = pd.DataFrame(X, columns = X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over 1000 2019-05-09 15:30:26.542512\n",
      "over 5000 2019-05-09 15:30:27.124286\n",
      "over 50000 2019-05-09 15:30:32.209716\n",
      "over 100000 2019-05-09 15:30:37.095945\n",
      "over 150000 2019-05-09 15:30:42.438605\n"
     ]
    }
   ],
   "source": [
    "check_steps = [1000,5000,50000,100000, 150000]    \n",
    "\n",
    "#X_temp = np.zeros((dim_0, time_step, dim_1))\n",
    "X_temp = []\n",
    "# pay attention, setting limit below should not go over total data length -1000 (no data enrichment beyond)\n",
    "\n",
    "''' too early for conversion to array \n",
    "for i in range(time_step,dim_0):\n",
    "    X_temp[i] = X[i-time_step:i]    \n",
    "# progress monitoring        \n",
    "    if i in check_steps:\n",
    "        print(\"over {}\".format(i),datetime.datetime.fromtimestamp(time.time()))       \n",
    "#X_10 = X_temp[r[0] == 1 for r in y]\n",
    "'''\n",
    "# build l10/H10 training kit\n",
    "\n",
    "y_temp_10 = []\n",
    "y_temp_50 = []\n",
    "y_temp_100 = []\n",
    "y_temp_1000 = []\n",
    "y_temp_other = []\n",
    "\n",
    "X_temp_10 = [] # col 0 or 4\n",
    "X_temp_50 = [] # col 1 or 5\n",
    "X_temp_100 = [] # col 2 or 6\n",
    "X_temp_1000 = [] # col 3 or 7\n",
    "X_temp_other = [] # other\n",
    "\n",
    "for i in range(time_step,dim_0):\n",
    "#    X_temp.append(X[i-time_step:i].values.tolist())\n",
    "#    if y[\"is_l10\"][i] + y[\"is_h10\"][i] > 0:\n",
    "#        X_temp_10.append(X[i-time_step:i].values.tolist())\n",
    "#        y_temp_10.append(y.iloc[i,[0,4]].values.tolist())\n",
    "#        if y[\"is_l50\"][i] + y[\"is_h50\"][i] > 0:\n",
    "#            X_temp_50.append(X[i-time_step:i].values.tolist())\n",
    "#            y_temp_50.append(y.iloc[i,[1,5]].values.tolist())\n",
    "    if y[\"is_l100\"][i] + y[\"is_h100\"][i] > 0:\n",
    "        X_temp_100.append(X[i-time_step:i].values)\n",
    "        y_temp_100.append(y.iloc[i,[2,6]].values)\n",
    "        if y[\"is_l1000\"][i] + y[\"is_h1000\"][i] >0:\n",
    "            X_temp_1000.append(X[i-time_step:i].values)\n",
    "            y_temp_1000.append(y.iloc[i,[3,7]].values)\n",
    "#    else:\n",
    "#        X_temp_other.append(X[i-time_step:i].values.tolist())\n",
    "#        y_temp_other.append(y.iloc[i,[0,4]].values.tolist())\n",
    "\n",
    "# progress monitoring        \n",
    "    if i in check_steps:\n",
    "        print(\"over {}\".format(i),datetime.datetime.fromtimestamp(time.time()))       \n",
    "#X_10 = X_temp[r[0] == 1 for r in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp_other = []\n",
    "y_temp_other = []\n",
    "samp100_ind = X[y[\"is_l100\"] + y[\"is_h100\"] == 0].sample(len(y_temp_100)).index\n",
    "for i in samp100_ind:\n",
    "    X_temp_other.append(X[i-time_step:i].values)\n",
    "    y_temp_other.append(y.iloc[i,[3,7]].values)\n",
    "\n",
    "X_100 = X_temp_100 + X_temp_other\n",
    "y_100 = y_temp_100 + y_temp_other\n",
    "\n",
    "X_temp_other = []\n",
    "y_temp_other = []\n",
    "samp1000_ind = X[y[\"is_l1000\"] + y[\"is_h1000\"] == 0].sample(len(y_temp_1000)).index\n",
    "for i in samp1000_ind:\n",
    "    X_temp_other.append(X[i-time_step:i].values)\n",
    "    y_temp_other.append(y.iloc[i,[3,7]].values)\n",
    "\n",
    "X_1000 = X_temp_1000 + X_temp_other\n",
    "y_1000 = y_temp_1000 + y_temp_other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800 1000 1\n",
      "over 1000 2019-05-09 15:34:45.772455\n",
      "over 5000 2019-05-09 15:34:49.407311\n",
      "(12800, 1000) 8960 10880\n"
     ]
    }
   ],
   "source": [
    "def array_conv(file_x, file_y):\n",
    "    dim1 = len(file_x)\n",
    "    dim2 = len(file_x[0])\n",
    "    dim3 = len(file_x[0][0])\n",
    "    dim4 = len(file_y[0])\n",
    "#   result_x = np.zeros((dim1, dim2, dim3))\n",
    "    result_x = np.zeros((dim1, dim2))\n",
    "    result_y = np.zeros((dim1,dim4))\n",
    "    \n",
    "    cpt_error = 0\n",
    "    \n",
    "    print(dim1,dim2,dim3)    \n",
    "    \n",
    "    for a in range(dim1-1):\n",
    "        if a in check_steps:\n",
    "            print(\"over {}\".format(a),datetime.datetime.fromtimestamp(time.time()))       \n",
    "        for b in range(dim2-1):\n",
    "\n",
    "# specific for CNN preparation\n",
    "            try:\n",
    "                result_x[a][b] = np.array(file_x[a][b])\n",
    "            except:\n",
    "                result_x[a][b] = 0\n",
    "                cpt_error += 1\n",
    "    return result_x, result_y\n",
    "'''\n",
    "            for c in range(dim3-1):            \n",
    "                try:\n",
    "                    result_x[a][b][c] = np.array(file_x[a][b][c])\n",
    "                except:\n",
    "                    result_x[a][b][c] = 0\n",
    "                    cpt_error += 1\n",
    "        result_y[a] = np.array(file_y[a])\n",
    "'''\n",
    "            \n",
    "\n",
    "    \n",
    "def arr_to_files(X_inp,y_inp, pref):   \n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['x'] = [r.tolist() for r in X_inp]\n",
    "    temp_df['y'] = [r.tolist() for r in y_inp]\n",
    "    temp_df = temp_df.sample(frac = 1)\n",
    "    x_inp = temp_df['x'].values\n",
    "    y_inp = temp_df['y'].values\n",
    "\n",
    "    #    del_line = len(X_temp)%batch\n",
    "   \n",
    "    train_lim = int(len(X_inp)*0.7) # training set length\n",
    "    val_lim = int(len(X_inp)*0.85)  # validation set length\n",
    "    \n",
    "    X_inp, y_inp = array_conv(X_inp, y_inp)\n",
    "    \n",
    "    print(X_inp.shape, train_lim,val_lim)\n",
    "    \n",
    "    X_train = X_inp[0:train_lim]\n",
    "    X_val = X_inp[train_lim:val_lim]\n",
    "    X_test = X_inp[val_lim:]\n",
    "    y_train = y_inp[0:train_lim]\n",
    "    y_val =  y_inp[train_lim:val_lim]\n",
    "    y_test =  y_inp[val_lim:]\n",
    "    \n",
    "#    print(pref,'\\n', X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)\n",
    "#    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    np.save(pref+'x_train',X_train)\n",
    "    np.save(pref+'x_val',X_val)\n",
    "    np.save(pref+'x_test',X_test)\n",
    "    np.save(pref+'y_train',y_train)\n",
    "    np.save(pref+'y_val',y_val)\n",
    "    np.save(pref+'y_test',y_test)\n",
    "#    return X_train, y_train\n",
    "\n",
    "#arr_to_files(X_100,y_100,'traintest/100_')\n",
    "arr_to_files(X_1000,y_1000,'traintest/1000_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-931765772341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
